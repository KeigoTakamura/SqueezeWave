--- inference.py
+++ inference.py
@@ -32,27 +32,31 @@ from scipy.io.wavfile import write
 import torch
 from mel2samp import files_to_list, MAX_WAV_VALUE
 from denoiser import Denoiser
-
+import time
 
 def main(mel_files, squeezewave_path, sigma, output_dir, sampling_rate, is_fp16,
          denoiser_strength):
     mel_files = files_to_list(mel_files)
-    squeezewave = torch.load(squeezewave_path)['model']
+
+    #device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
+    device = torch.device('cpu')   
+    squeezewave = torch.load(squeezewave_path,map_location=device) ['model']
     squeezewave = squeezewave.remove_weightnorm(squeezewave)
-    squeezewave.cuda().eval()
+    squeezewave.eval()
     if is_fp16:
         from apex import amp
-        squeezewave, _ = amp.initialize(squeezewave, [], opt_level="O3")
+        squeezewave, _ = amp.initialize(squeezewave,[],opt_level="O3")
 
     if denoiser_strength > 0:
-        denoiser = Denoiser(squeezewave).cuda()
-
+        denoiser = Denoiser(squeezewave)
+    start = time.time()
     for i, file_path in enumerate(mel_files):
         file_name = os.path.splitext(os.path.basename(file_path))[0]
-        mel = torch.load(file_path)
-        mel = torch.autograd.Variable(mel.cuda())
-        mel = torch.unsqueeze(mel, 0)
-        mel = mel.half() if is_fp16 else mel
+        mel = torch.load(file_path,map_location=device)
+        mel = torch.autograd.Variable(mel)
+        #mel = torch.unsqueeze(mel, 0)
+        #mel = mel.half() if is_fp16 else mel
+        mel = mel.half() 
         with torch.no_grad():
             audio = squeezewave.infer(mel, sigma=sigma).float()
             if denoiser_strength > 0:
